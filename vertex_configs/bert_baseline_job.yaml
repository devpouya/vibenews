# Vertex AI Job Configuration for BERT Baseline
experiment_name: "bert_baseline_vertex"
description: "BERT-base training on Vertex AI with BABE dataset"
tags: ["vertex-ai", "bert", "baseline"]

model:
  architecture: "bert"
  model_name: "bert-base-uncased"
  num_labels: 3
  dropout: 0.1
  freeze_layers: 0

training:
  batch_size: 16
  eval_batch_size: 64
  learning_rate: 2.0e-5
  epochs: 3
  warmup_steps: 500
  weight_decay: 0.01
  max_grad_norm: 1.0
  scheduler: "linear"
  optimizer: "adamw"

data:
  dataset: "babe"
  train_split: 0.8
  preprocessing: "none"
  max_length: 512
  data_source: "gcs"
  filter_no_agreement: false

logging:
  tensorboard: true
  log_steps: 100
  eval_steps: 500
  save_steps: 1000
  log_confusion_matrix: true
  log_predictions: true

vertex:
  machine_type: "n1-standard-4"
  accelerator_type: "NVIDIA_TESLA_T4"
  accelerator_count: 1
  disk_type: "pd-ssd"
  disk_size_gb: 100
  preemptible: true
  max_replica_count: 1